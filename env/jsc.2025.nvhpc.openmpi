# --------------------------------------------------------------------------
# Loads IntelLLVM+ParaStationMPI build environment for TSMP2.
# This environment is tailored for JURECA [1] and JUWELS [2] supercomputers.
#
# [1] https://apps.fz-juelich.de/jsc/software/jureca/index.xhtml
# [2] https://apps.fz-juelich.de/jsc/software/juwels/index.xhtml
# 
# Usage: source jsc.2025.intel.psmpi
# --------------------------------------------------------------------------

# Load Stages/2025
module --force purge
module use $OTHERSTAGES
module load Stages/2025
module load NVHPC/25.5-CUDA-12
module load OpenMPI
module load ScaLAPACK/2.2.0-fb

# Basic scripting and build tools
module load Python
module load CMake
module load git

# Storage libraries
module load HDF5
module load netCDF
module load netCDF-Fortran
module load PnetCDF

# ParFlow additional libraries
module load CUDA
module load UCX-settings/RC-CUDA
module load Hypre/2.31.0

# TODO: Verify these values
if [[ $SYSTEMNAME == "jedi" || $SYSTEMNAME == "jupiter" ]]; then
  export CUDAARCHS="90"
else
  export CUDAARCHS="80"
fi
export CMAKE_CUDA_RUNTIME_LIBRARY="Shared"


# ICON additional libraries
module load ecCodes

# Set default MPI compilers
export OMPI_CC=nvc
export OMPI_CXX=nvc++
export OMPI_FC=nvfortran
export CC=mpicc
export FC=mpif90
export CXX=mpicxx
export MPI_HOME=$EBROOTOPENMPI

# Display compiler settings
module list
echo "=========================== COMPILER SETTINGS  =======================" 
echo "   Machine: ${SYSTEMNAME} on Stages/$STAGE"
echo "   MPI lib: $(mpirun --version | head -n 1)"
echo "         C: $($CC --version | head -n 2 | tail -n 1)"
echo "       C++: $($CXX --version | head -n 2 | tail -n 1)"
echo "   Fortran: $($FC --version | head -n 2 | tail -n 1)"
echo "======================================================================"

